# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VvMMBjrlTgW_W2RAaKFEzyRsmweTB_z5
"""

import numpy as np
import pandas as pd
import json

train = json.load(open("/content/ML Challenge/train.json"))
test=json.load(open("/content/ML Challenge/test.json"))

df_train = pd.DataFrame(train)
df_train.head()
df_train.info()
df_train.describe()

df_test = pd.DataFrame(test)
df_test.head()
df_test.describe()

from collections import Counter

fac_series = df_train["facilities"].fillna("").astype(str)

def get_ngrams(tokens, n):
    return [" ".join(tokens[i:i+n]) for i in range(len(tokens) - n + 1)]

unigrams = Counter()
bigrams  = Counter()
trigrams = Counter()

for txt in fac_series:
    tokens = txt.split()
    unigrams.update(tokens)
    bigrams.update(get_ngrams(tokens, 2))
    trigrams.update(get_ngrams(tokens, 3))

for word, count in unigrams.most_common():
    print(f"{word}: {count}")

amenity_categories = {
    "Cooking": [
        "kitchen", "cooking", "stove", "oven",
        "bbq", "grill", "barbecue", "utensils",
        "microwave", "dishwasher",
        "glasses", "dinnerware",
        "rice", "toaster",
    ],
    "FoodStorage": [
        "refrigerator", "freezer", "fridge",
    ],
    "Laundry": [
        "washer", "dryer", "laundromat",
        "drying", "rack", "clothing", "iron",
    ],
    "Safety": [
        "smoke",
        "carbon monoxide",
        "fire extinguisher",
        "first aid kit",
        "safety",
        "gates",
        "safe",
        "guards",
    ],
    "Entertainment": [
        "books", "reading",
        "board games",
        "game console",
        "ping pong",
        "piano",
        "arcade",
        "movie theater",
        "record player",
        "sound system",
        "toys",
    ],
    "Internet": [
        "wifi", "ethernet", "connection",
    ],
    "Climate": [
        "air conditioning",
        "heating",
        "portable fans",
        "ceiling fan",
        "indoor fireplace",
        "fireplace",
    ],
    "Bathroom": [
        "hair dryer",
        "shampoo",
        "conditioner",
        "bathtub",
        "bidet",
        "shower gel",
        "body soap",
        "bath",
        "tub",
    ],
    "Parking": [
        "parking",
        "ev charger",
    ],
    "Leisure": [
        "patio", "balcony",
        "outdoor",
        "backyard",
        "furniture",
        "beach access",
        "pool",
        "waterfront",
        "hammock",
        "sun loungers",
        "lake",
        "kayak",
        "resort",
        "bikes",
        "boat slip",
        "ski-in/ski-out",
        "climbing wall",
        "bowling alley",
    ],
    "Child": [
        "crib",
        "pack ’n play/travel crib",
        "pack 'n play/travel crib",
        "children’s", "children's",
        "baby",
        "high chair",
        "playroom",
        "babysitter",
        "safety gates",
        "outlet covers",
    ],
    "Work": [
        "dedicated workspace",
        "desk",
    ],
    "Breakfast": [
        "breakfast",
    ],
    "PrivateAccess": [
        "private", "entrance",
    ],
    "LongStay": [
        "long term stays",
    ],
    "Drink": [
        "coffee", "wine", "kettle",
    ],
}


def contains_any(text, phrases):
    text = text.lower()
    for p in phrases:
        if p in text:
            return 1
    return 0

def check_phrase_in_row(text, phrases):
    return contains_any(text, phrases)

def add_amenity_binary_columns(df, facilities_col="facilities"):
    df[facilities_col] = df[facilities_col].fillna("").astype(str)
    for cat_name, phrases in amenity_categories.items():
        col_name = f"amenity_{cat_name.lower()}"
        df[col_name] = df[facilities_col].apply(
            check_phrase_in_row,
            phrases=phrases
        )

    return df

df_train = add_amenity_binary_columns(df_train, facilities_col="facilities")
df_test  = add_amenity_binary_columns(df_test,  facilities_col="facilities")

df_train

df_train["host"] = df_train["host"].fillna("Unknown").astype(str)
df_test["host"]  = df_test["host"].fillna("Unknown").astype(str)
df_all_hosts = pd.concat([df_train[["host"]], df_test[["host"]]])
host_counts_global = df_all_hosts["host"].value_counts()
df_train["host_count"] = df_train["host"].map(host_counts_global).astype(int)
df_test["host_count"]  = df_test["host"].map(host_counts_global).astype(int)
df_train = df_train.drop(columns=["host", "name"], errors="ignore")
df_test  = df_test.drop(columns=["host", "name"], errors="ignore")

df_train

!pip install xgboost

!pip install optuna

from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split


drop_cols_train = ["occupancy", "facilities"]
drop_cols_test  = ["facilities"]

X = df_train.drop(columns=drop_cols_train)
y = df_train["occupancy"]
X_test = df_test.drop(columns=drop_cols_test)

from sklearn.preprocessing import LabelEncoder

categorical_cols = ["room_type", "listing_type", "cancellation"]

encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    combined = pd.concat([df_train[col].fillna("Unknown").astype(str),
                          df_test[col].fillna("Unknown").astype(str)])
    le.fit(combined)
    X[col]      = le.transform(df_train[col].fillna("Unknown").astype(str))
    X_test[col] = le.transform(df_test[col].fillna("Unknown").astype(str))
    encoders[col] = le

X_train, X_val, y_train, y_val = train_test_split(
    X, y,
    test_size=0.2,
    shuffle=True,
    random_state=42
)

model_xgb = XGBRegressor(
    n_estimators=2000,
    learning_rate=0.03,
    max_depth=9,
    subsample=0.8,
    colsample_bytree=0.8,
    objective="reg:absoluteerror",   # MAE
    random_state=42,
    tree_method="hist"
)

model_xgb.fit(X_train, y_train)


y_pred = model_xgb.predict(X_val)
mae_xgb = mean_absolute_error(y_val, y_pred)

print("\n===========================")
print(" XGBoost Validation MAE =", mae_xgb)
print("===========================\n")

import optuna
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split

def objective(trial):
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 1000, 4000),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.1),
        "max_depth": trial.suggest_int("max_depth", 4, 12),
        "subsample": trial.suggest_float("subsample", 0.6, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.6, 1.0),
        "min_child_weight": trial.suggest_int("min_child_weight", 1, 10),
        "reg_alpha": trial.suggest_float("reg_alpha", 0.0, 3.0),
        "reg_lambda": trial.suggest_float("reg_lambda", 0.1, 3.0),
        "objective": "reg:absoluteerror",
        "random_state": 42,
        "tree_method": "hist",
    }

    model = XGBRegressor(**params)

    X_tr, X_val, y_tr, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42, shuffle=True
    )

    model.fit(X_tr, y_tr)
    preds = model.predict(X_val)
    mae = mean_absolute_error(y_val, preds)
    return mae

study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=50)

print("Best parameters:", study.best_params)
print("Best MAE:", study.best_value)

from sklearn.model_selection import KFold
from sklearn.metrics import mean_absolute_error
from xgboost import XGBRegressor
import numpy as np


best_params = {
    'n_estimators': 1613,
    'learning_rate': 0.030604944785767443,
    'max_depth': 8,
    'subsample': 0.859156224928918,
    'colsample_bytree': 0.6969180835768004,
    'min_child_weight': 1,
    'reg_alpha': 2.246202539505531,
    'reg_lambda': 1.5721406691212654
}

# ثابت‌های مدل
best_params["objective"] = "reg:absoluteerror"
best_params["random_state"] = 42
best_params["tree_method"] = "hist"

kf = KFold(n_splits=5, shuffle=True, random_state=42)

oof_preds = np.zeros(len(X))   # out-of-fold predictions
fold_maes = []

for fold, (train_idx, val_idx) in enumerate(kf.split(X)):
    print(f"\n========== Fold {fold+1} ==========")
    X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]

    model = XGBRegressor(**best_params)

    model.fit(X_tr, y_tr)

    val_pred = model.predict(X_val)
    oof_preds[val_idx] = val_pred

    fold_mae = mean_absolute_error(y_val, val_pred)
    fold_maes.append(fold_mae)
    print(f"Fold {fold+1} MAE: {fold_mae:.6f}")

overall_mae = mean_absolute_error(y, oof_preds)
print("\n===============================")
print("Fold MAEs:", [round(m, 6) for m in fold_maes])
print("K-Fold Overall MAE:", overall_mae)
print("===============================")

import zipfile
best_params = {
    'n_estimators': 1613,
    'learning_rate': 0.030604944785767443,
    'max_depth': 8,
    'subsample': 0.859156224928918,
    'colsample_bytree': 0.6969180835768004,
    'min_child_weight': 1,
    'reg_alpha': 2.246202539505531,
    'reg_lambda': 1.5721406691212654
}

best_params["objective"] = "reg:absoluteerror"   # MAE
best_params["random_state"] = 42
best_params["tree_method"] = "hist"


final_model = XGBRegressor(**best_params)


final_model.fit(X, y)


y_test_pred = final_model.predict(X_test)


pred_list = [{"occupancy": float(v)} for v in y_test_pred]


with open("predicted.json", "w") as f:
    json.dump(pred_list, f, indent=2)


with zipfile.ZipFile("predicted.zip", "w", zipfile.ZIP_DEFLATED) as z:
    z.write("predicted.json")

print("✅ predicted.json و predicted.zip ساخته شدند.")